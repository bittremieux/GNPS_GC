{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "import functools\n",
    "import http\n",
    "import json\n",
    "import logging\n",
    "import os\n",
    "import urllib\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as mticker\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from matplotlib_venn import venn3, venn3_circles\n",
    "from rdkit import Chem\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use(['seaborn-white', 'seaborn-paper'])\n",
    "plt.rc('font', family='serif')\n",
    "sns.set_palette('Set1')\n",
    "sns.set_context('paper', font_scale=1.3)\n",
    "\n",
    "tqdm.pandas(leave=False)\n",
    "\n",
    "logging.basicConfig(format='%(asctime)s [%(levelname)s/%(processName)s] '\n",
    "                           '%(module)s.%(funcName)s : %(message)s',\n",
    "                    level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@functools.lru_cache(None)\n",
    "def pubchem_name_to_inchikey(name):\n",
    "    try:\n",
    "        with urllib.request.urlopen(\n",
    "                f'https://pubchem.ncbi.nlm.nih.gov/rest/pug/compound/name/'\n",
    "                f'{name}/property/inchikey/TXT') as f_url:\n",
    "            return f_url.read().decode().strip().split()[0]\n",
    "    except urllib.error.HTTPError:\n",
    "        return None\n",
    "\n",
    "    \n",
    "@functools.lru_cache(None)\n",
    "def smiles_to_inchikey(smiles):\n",
    "    try:\n",
    "        mol = Chem.rdmolfiles.MolFromSmiles(smiles)\n",
    "    except ValueError:\n",
    "        mol = None\n",
    "    return Chem.rdinchi.MolToInchiKey(mol) if mol is not None else None\n",
    "\n",
    "\n",
    "@functools.lru_cache(None)\n",
    "def inchikey_to_subclass(inchikey):\n",
    "    try:\n",
    "        with urllib.request.urlopen(f'https://gnps-classyfire.ucsd.edu/'\n",
    "                                    f'entities/{inchikey}.json') \\\n",
    "                as f_url:\n",
    "            return json.loads(f_url.read())['subclass']['chemont_id']\n",
    "    except (urllib.error.HTTPError, AttributeError, TypeError, KeyError):\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '../data/deconvolution_comparison'\n",
    "compounds = {\n",
    "    'Metabolomics Workbench ST001154':\n",
    "        set(pd.read_csv(os.path.join(\n",
    "            data_dir, 'Metabolomics Workbench ST001154.csv'))['InChiKey']),\n",
    "    'LECO beer aging':\n",
    "        set(pd.read_csv(os.path.join(data_dir, 'LECO beer aging.csv'))\n",
    "            ['Name'].apply(pubchem_name_to_inchikey))\n",
    "}\n",
    "subclasses = {dataset: set([inchikey_to_subclass(inchikey)\n",
    "                            for inchikey in comp])\n",
    "              for dataset, comp in compounds.items()}\n",
    "for sc in subclasses.values():\n",
    "    sc.discard(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_ids = {\n",
    "    'Metabolomics Workbench ST001154': {\n",
    "        'MSHub': '4f2de61a', 'MZmine': '021f4818', 'MS-DIAL': '16d202bd'},\n",
    "    'LECO beer aging': {\n",
    "        'MSHub': '35445438', 'MZmine': '37971f05', 'MS-DIAL': 'dd21a47e'}}\n",
    "\n",
    "identifications = collections.defaultdict(\n",
    "    lambda: collections.defaultdict(dict))\n",
    "for top in (1, 10):\n",
    "    for dataset, tools in task_ids.items():\n",
    "        logging.info('Process %s', dataset)\n",
    "        for tool, task_id in tools.items():\n",
    "            logging.info('%s identifications', tool)\n",
    "            # Read the GNPS task file.\n",
    "            usecols = ['#Scan#', 'INCHI', 'Smiles', 'MQScore', 'SharedPeaks']\n",
    "            if tool == 'MSHub':\n",
    "                usecols.append('Balance_score(percentage)')\n",
    "            ids = (\n",
    "                pd.read_csv(\n",
    "                    os.path.join(\n",
    "                        data_dir, f'MOLECULAR-LIBRARYSEARCH-GC-{task_id}-'\n",
    "                        f'view_all_annotations_DB-main.tsv'),\n",
    "                    sep='\\t', usecols=usecols, skipinitialspace=True)\n",
    "                .dropna()\n",
    "                .sort_values(['#Scan#', 'MQScore'], ascending=[True, False])\n",
    "                .groupby('#Scan#').head(top))\n",
    "            # Require a minimum cosine score of 0.8 and\n",
    "            # more than 10 matched peaks.\n",
    "            ids = ids[(ids['MQScore'] > 0.8) & (ids['SharedPeaks'] > 10)]\n",
    "            # Use only the top match per compound.\n",
    "            ids = (ids.sort_values('MQScore', ascending=False)\n",
    "                   .drop_duplicates('INCHI'))\n",
    "            # Get InChIKeys and subclasses for all identifications.\n",
    "            ids['InChIKey'] = ids['Smiles'].apply(smiles_to_inchikey)\n",
    "            ids['subclass'] = \\\n",
    "                ids['InChIKey'].progress_apply(inchikey_to_subclass)\n",
    "            ids.dropna()\n",
    "            \n",
    "            identifications[top][dataset][tool] = ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tops, datasets, tools, match_type, perc_matched = [], [], [], [], []\n",
    "for top, dataset_ids in identifications.items():\n",
    "    for dataset, tool_ids in dataset_ids.items():\n",
    "        for tool, ids in tool_ids.items():\n",
    "            tops.append(top)\n",
    "            datasets.append(dataset)\n",
    "            tools.append(tool)\n",
    "            match_type.append('Direct match')\n",
    "            perc_matched.append(\n",
    "                len(set(ids['InChIKey']) & compounds[dataset])\n",
    "                / len(compounds[dataset]))\n",
    "            tops.append(top)\n",
    "            datasets.append(dataset)\n",
    "            tools.append(tool)\n",
    "            match_type.append('Subclass match')\n",
    "            perc_matched.append(\n",
    "                len(set(ids['subclass']) & subclasses[dataset])\n",
    "                / len(subclasses[dataset]))\n",
    "\n",
    "matched = pd.DataFrame({'Dataset': datasets, 'Tool': tools, 'Top': tops,\n",
    "                        'Type': match_type,\n",
    "                        'Compounds identified': perc_matched})\n",
    "\n",
    "g = sns.catplot(x='Tool', y='Compounds identified', hue='Type', data=matched,\n",
    "                row='Dataset', col='Top', kind='bar', height=4, aspect=1.5,\n",
    "                legend=False)\n",
    "\n",
    "for ax in g.axes.ravel():\n",
    "    ax.set_ylim(0, 1)\n",
    "    ax.yaxis.set_major_formatter(mticker.PercentFormatter(1))\n",
    "\n",
    "g.axes[0, -1].legend(loc='upper center', bbox_to_anchor=(0, 1.35),\n",
    "                     title='Type', fontsize='medium', ncol=2)\n",
    "\n",
    "sns.despine()\n",
    "\n",
    "plt.savefig('deconvolution_comparison.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "height = 8\n",
    "width = height\n",
    "num_col = len(identifications)\n",
    "num_row = len(identifications[1])\n",
    "fig, axes = plt.subplots(\n",
    "    num_row, num_col, figsize=(width * num_col, height * num_row))\n",
    "\n",
    "for col, (top, top_ids) in enumerate(identifications.items()):\n",
    "    for row, (dataset, dataset_ids) in enumerate(top_ids.items()):\n",
    "        ax = axes[row, col]\n",
    "        \n",
    "        sets = []\n",
    "        for tool, tool_ids in dataset_ids.items():\n",
    "            sets.append(set(tool_ids[tool_ids['InChIKey'].isin(\n",
    "                compounds[dataset])]['InChIKey']))\n",
    "        v = venn3(sets, set_labels=dataset_ids.keys(), ax=ax)\n",
    "        c = venn3_circles(sets, linewidth=1.0, ax=ax)\n",
    "        for text in v.subset_labels:\n",
    "            if text is not None:\n",
    "                text.set_fontsize('large')\n",
    "\n",
    "        ax.set_title(f'Dataset = {dataset} | Top = {top}', fontsize='large')\n",
    "\n",
    "plt.savefig('deconvolution_comparison_venn_direct_match.png',\n",
    "            dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "height = 8\n",
    "width = height\n",
    "num_col = len(identifications)\n",
    "num_row = len(identifications[1])\n",
    "fig, axes = plt.subplots(\n",
    "    num_row, num_col, figsize=(width * num_col, height * num_row))\n",
    "\n",
    "for col, (top, top_ids) in enumerate(identifications.items()):\n",
    "    for row, (dataset, dataset_ids) in enumerate(top_ids.items()):\n",
    "        ax = axes[row, col]\n",
    "        \n",
    "        sets = []\n",
    "        for tool, tool_ids in dataset_ids.items():\n",
    "            sets.append(set(tool_ids[tool_ids['subclass'].isin(\n",
    "                subclasses[dataset])]['subclass']))\n",
    "        v = venn3(sets, set_labels=dataset_ids.keys(), ax=ax)\n",
    "        c = venn3_circles(sets, linewidth=1.0, ax=ax)\n",
    "        for text in v.subset_labels:\n",
    "            if text is not None:\n",
    "                text.set_fontsize('large')\n",
    "\n",
    "        ax.set_title(f'Dataset = {dataset} | Top = {top}', fontsize='large')\n",
    "\n",
    "plt.savefig('deconvolution_comparison_venn_subclass_match.png',\n",
    "            dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cosines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cosines.set_index(order).sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tops, datasets, tools, cosines = [], [], [], []\n",
    "for top, top_ids in identifications.items():\n",
    "    for dataset, dataset_ids in top_ids.items():\n",
    "        for tool, tool_ids in dataset_ids.items():\n",
    "            ids = tool_ids[tool_ids['InChIKey'].isin(compounds[dataset])]\n",
    "            tops.extend([top] * len(ids))\n",
    "            datasets.extend([dataset] * len(ids))\n",
    "            tools.extend([tool] * len(ids))\n",
    "            cosines.extend(ids['MQScore'].values)\n",
    "min_balance_scores = [60, 80]\n",
    "for min_balance_score in min_balance_scores:\n",
    "    for top, top_ids in identifications.items():\n",
    "        for dataset, dataset_ids in top_ids.items():\n",
    "            ids = dataset_ids['MSHub']\n",
    "            ids = ids[(ids['InChIKey'].isin(compounds[dataset])) &\n",
    "                      (ids['Balance_score(percentage)'] > min_balance_score)]\n",
    "            tops.extend([top] * len(ids))\n",
    "            datasets.extend([dataset] * len(ids))\n",
    "            tools.extend([f'MSHub\\n(Balance score > {min_balance_score}%)']\n",
    "                         * len(ids))\n",
    "            cosines.extend(ids['MQScore'].values)\n",
    "\n",
    "cosines = pd.DataFrame({'Top': tops, 'Dataset': datasets, 'Tool': tools,\n",
    "                        'Cosine score': cosines})\n",
    "# Custom sort to group MSHub results.\n",
    "order = cosines['Tool'].replace({\n",
    "    'MSHub': 0, 'MSHub\\n(Balance score > 60%)': 1,\n",
    "    'MSHub\\n(Balance score > 80%)': 2, 'MZmine': 3, 'MS-DIAL': 4})\n",
    "cosines = cosines.set_index(order).sort_index()\n",
    "\n",
    "g = sns.catplot(x='Tool', y='Cosine score', hue='Top', data=cosines,\n",
    "                row='Dataset', kind='violin', height=4, aspect=3,\n",
    "                legend=False, cut=0, scale='count', inner='point')\n",
    "\n",
    "g.axes[0, -1].legend(loc='upper center', bbox_to_anchor=(0.5, 1.35),\n",
    "                     title='Top', fontsize='medium', ncol=2)\n",
    "\n",
    "sns.despine()\n",
    "\n",
    "plt.savefig('deconvolution_cosine_score.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "height = 6\n",
    "width = height * 1.5\n",
    "fig, ax = plt.subplots(figsize=(width, height))\n",
    "\n",
    "tops, datasets, balance_scores = [], [], []\n",
    "for top, top_ids in identifications.items():\n",
    "    for dataset, dataset_ids in top_ids.items():\n",
    "        ids = dataset_ids['MSHub']\n",
    "        ids = ids[ids['InChIKey'].isin(compounds[dataset])]\n",
    "        tops.extend([top] * len(ids))\n",
    "        datasets.extend([dataset] * len(ids))\n",
    "        balance_scores.extend(ids['Balance_score(percentage)'].values)\n",
    "\n",
    "balance_scores = pd.DataFrame({'Top': tops, 'Dataset': datasets,\n",
    "                               'Balance score': balance_scores})\n",
    "sns.violinplot(x='Dataset', y='Balance score', hue='Top',\n",
    "               data=balance_scores, cut=0, scale='count', inner='point')\n",
    "\n",
    "ax.yaxis.set_major_formatter(mticker.PercentFormatter(100))\n",
    "\n",
    "ax.legend(loc='upper left', bbox_to_anchor=(1, 1), title='Top')\n",
    "\n",
    "sns.despine()\n",
    "\n",
    "plt.savefig('deconvolution_balance_score.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.shutdown()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
